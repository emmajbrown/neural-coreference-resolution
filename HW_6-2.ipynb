{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "HW_6.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-Mh8KqXb0yR8"
      },
      "source": [
        "# Homework 6: Neural Coreference Resolution\n",
        "\n",
        "**Due April 20, 2020 at 11:59pm**\n",
        "\n",
        "In this homework,  you will be implementing parts of a Pytorch implementation for neural coreference resolution, inspired by [Lee et al.(2017), “End-to-end Neural Coreference Resolution” (EMNLP)](https://arxiv.org/pdf/1707.07045.pdf). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2UqglTYOZ9jd"
      },
      "source": [
        "### REMEMBER TO UPLOAD THE DATASET!\n",
        "Click the Files icon > Upload > Upload train.conll and dev.conll that you have downloaded from bCourses: Files/HW_6"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rpxETEnm1c0h"
      },
      "source": [
        "### Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "d7u1xOC_zcEG",
        "colab": {}
      },
      "source": [
        "import sys, re\n",
        "from collections import Counter\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.optim as optim\n",
        "\n",
        "import numpy as np\n",
        "from scipy.stats import spearmanr"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "X1Wm71YOajw0"
      },
      "source": [
        "We noticed that running this on CPU is faster than running on GPU. Thus, we will default to running on CPU. However, feel free to change it to GPU if you wish."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "r5qiaj6zzfSN",
        "outputId": "60f27b93-0977-4249-b8fd-4c8603135612",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "device = torch.device(\"cpu\")\n",
        "print(\"Running on {}\".format(device))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running on cpu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6qTmWIJq56IA"
      },
      "source": [
        "### Download and process data\n",
        "Note: You do **not** have to modify this section."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EDP_KFPo7N12",
        "outputId": "81f8ba77-3213-4736-c703-454f07a8871e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        }
      },
      "source": [
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip glove*.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-04-27 03:56:31--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2020-04-27 03:56:31--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2020-04-27 03:56:31--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  2.07MB/s    in 6m 29s  \n",
            "\n",
            "2020-04-27 04:03:00 (2.11 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n",
            "Archive:  glove.6B.zip\n",
            "  inflating: glove.6B.50d.txt        \n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JRDDk-tu-EfJ",
        "colab": {}
      },
      "source": [
        "def read_conll(filename):\n",
        "\n",
        "  docid=None\n",
        "  partID=None\n",
        "\n",
        "  # collection\n",
        "  all_sents=[]\n",
        "  all_ents=[]\n",
        "\n",
        "  # for one doc\n",
        "  all_doc_sents=[]\n",
        "  all_doc_ents=[]\n",
        "\n",
        "  # for one sentence\n",
        "  sent=[]\n",
        "  ents=[]\n",
        "\n",
        "  named_ents=[]\n",
        "  cur_tid=0\n",
        "  open_count=0\n",
        "\n",
        "  global_eid=0\n",
        "  doc_eid_to_global_eid={}\n",
        "\n",
        "  with open(filename, encoding=\"utf-8\") as file:\n",
        "    for line in file:\n",
        "      if line.startswith(\"#begin document\"):\n",
        "\n",
        "        all_doc_ents=[]\n",
        "        all_doc_sents=[]\n",
        "\n",
        "        open_ents={}\n",
        "        open_named_ents={}\n",
        "\n",
        "        docid=None\n",
        "        matcher=re.match(\"#begin document \\((.*)\\); part (.*)$\", line.rstrip())\n",
        "        if matcher != None:\n",
        "          docid=matcher.group(1)\n",
        "          partID=matcher.group(2)\n",
        "\n",
        "      elif line.startswith(\"#end document\"):\n",
        "\n",
        "        all_sents.append(all_doc_sents)\n",
        "        all_ents.append(all_doc_ents)\n",
        "\n",
        "        \n",
        "      else:\n",
        "\n",
        "        parts=re.split(\"\\s+\", line.rstrip())\n",
        "\n",
        "        # sentence boundary\n",
        "        if len(parts) < 2:\n",
        "    \n",
        "          all_doc_sents.append(sent)\n",
        "\n",
        "          ents=sorted(ents, key=lambda x: (x[0], x[1]))\n",
        "\n",
        "          all_doc_ents.append(ents)\n",
        "\n",
        "          sent=[]\n",
        "          ents=[]\n",
        "\n",
        "          cur_tid=0\n",
        "\n",
        "          continue\n",
        "\n",
        "        tid=cur_tid\n",
        "        token=parts[3]\n",
        "        cur_tid+=1\n",
        "\n",
        "        identifier=\"%s.%s\" % (docid, partID)\n",
        "\n",
        "        coref=parts[-1].split(\"|\")\n",
        "\n",
        "        for c in coref:\n",
        "          if c.startswith(\"(\") and c.endswith(\")\"):\n",
        "            c=re.sub(\"\\(\", \"\", c)\n",
        "            c=int(re.sub(\"\\)\", \"\", c))\n",
        "\n",
        "            if (identifier, c) not in doc_eid_to_global_eid:\n",
        "              doc_eid_to_global_eid[(identifier, c)]=len(doc_eid_to_global_eid)\n",
        "\n",
        "            ents.append((tid, tid, doc_eid_to_global_eid[(identifier, c)], identifier))\n",
        "\n",
        "          elif c.startswith(\"(\"):\n",
        "            c=int(re.sub(\"\\(\", \"\", c))\n",
        "\n",
        "            if c not in open_ents:\n",
        "              open_ents[c]=[]\n",
        "            open_ents[c].append(tid)\n",
        "            open_count+=1\n",
        "\n",
        "          elif c.endswith(\")\"):\n",
        "            c=int(re.sub(\"\\)\", \"\", c))\n",
        "\n",
        "            assert c in open_ents\n",
        "\n",
        "            start_tid=open_ents[c].pop()\n",
        "            open_count-=1\n",
        "\n",
        "            if (identifier, c) not in doc_eid_to_global_eid:\n",
        "              doc_eid_to_global_eid[(identifier, c)]=len(doc_eid_to_global_eid)\n",
        "\n",
        "            ents.append((start_tid, tid, doc_eid_to_global_eid[(identifier, c)], identifier))\n",
        "\n",
        "        sent.append(token)\n",
        "\n",
        "  return all_sents, all_ents\n",
        "\n",
        "def load_embeddings(filename, vocab_size):\n",
        "  # 0 idx is for padding\n",
        "  # 1 idx is for unknown words\n",
        "\n",
        "  # get the embedding size from the first embedding\n",
        "  with open(filename, encoding=\"utf-8\") as file:\n",
        "    word_embedding_dim=len(file.readline().split(\" \"))-1\n",
        "\n",
        "  vocab={\"[PAD]\":0, \"[UNK]\":1}\n",
        "\n",
        "  print(\"word_embedding_dim:\", word_embedding_dim)\n",
        "\n",
        "  embeddings=np.zeros((vocab_size, word_embedding_dim))\n",
        "\n",
        "  with open(filename, encoding=\"utf-8\") as file:\n",
        "    for idx,line in enumerate(file):\n",
        "\n",
        "      if idx + 2 >= vocab_size:\n",
        "        break\n",
        "\n",
        "      cols=line.rstrip().split(\" \")\n",
        "      val=np.array(cols[1:])\n",
        "      word=cols[0]\n",
        "      embeddings[idx+2]=val\n",
        "      vocab[word]=idx+2\n",
        "\n",
        "  return torch.FloatTensor(embeddings), vocab"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "F17zKOXO6Cap",
        "outputId": "b093f3a1-e334-4f86-f6f3-28e10074ad39",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "embeddingFile = \"glove.6B.50d.txt\"\n",
        "trainFile = \"train.conll\"\n",
        "devFile = \"dev.conll\"\n",
        "\n",
        "all_sents, all_ents=read_conll(trainFile)\t\n",
        "dev_all_sents, dev_all_ents=read_conll(devFile)\n",
        "\n",
        "embeddings, vocab=load_embeddings(embeddingFile, 50000)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "word_embedding_dim: 50\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qeMhT6UN1eP5"
      },
      "source": [
        "### **Part 1. Implement B3**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "YshAEm0xd8NL"
      },
      "source": [
        "In this part, you’ll implement the B3 coreference metric as discussed in class without importing external libraries. \n",
        "\n",
        "Recall the definition: \n",
        "$B^{_{precision}^{3}} = \\frac{1}{n}\\sum_{i}^{n} \\frac{\\left |Gold_{i} \\cap  System_{i} \\right |}{\\left | System_{i} \\right |}$\n",
        "$B^{_{recall}^{3}} = \\frac{1}{n}\\sum_{i}^{n} \\frac{\\left |Gold_{i} \\cap  System_{i} \\right |}{\\left | Gold_{i} \\right |}$\n",
        "\n",
        "You should be able to pass the sanity check b3_test() after implementing it.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VpEJaiqez-bd",
        "colab": {}
      },
      "source": [
        "def b3(gold, system):\n",
        "  \"\"\" Calculate B3 metrics given the gold and system output\n",
        "    Args:\n",
        "        gold  : A dictionary that contains true references. The key is a tuple, (docid, absolute_start_idx, absolute_end_idx)\n",
        "                representing a target to be predicted; the value is the true reference entity id.\n",
        "        system: A dictionary that contains predicted referenece. The key in gold and system should be identical; the value\n",
        "                is the predicted entity generated by the model.\n",
        "    Returns:\n",
        "        precision, recall, F(following the formula above)\n",
        "\n",
        "    \"\"\"\n",
        "  # make this less based on this specific problem--need to find all indiv\n",
        "  # mentions that are unique in gold and system\n",
        "  # iterate through mentions, then find the rest of the mentions that are linked to that same entity as the initial mention\n",
        "  precision=0.\n",
        "  recall=0.\n",
        "  F = 0.\n",
        "  \n",
        "  #values = list(zip(gold.values(),system.values()))\n",
        "  zipped = list(zip(gold.values(),system.values()))\n",
        "  n = len(zipped)\n",
        "  tracking_gold = {}\n",
        "  tracking_system = {}\n",
        "  #for k,v in gold.items():\n",
        "    #k's will be the same for gold and system\n",
        "  for k, v in gold.items():\n",
        "    tracking_gold.setdefault(v, []).append(k)\n",
        "    tracking_system.setdefault(system[k],[]).append(k)\n",
        "  #print('track_gold',tracking_gold)\n",
        "  #print('track_system',tracking_system)\n",
        "  for tuples in zipped:\n",
        "    gold_values = tracking_gold[tuples[0]] # value=1\n",
        "    system_values = tracking_system[tuples[1]] # value = 5\n",
        "    num_common_elems = len(set(gold_values) & set(system_values)) #overlap\n",
        "    len_gold = len(gold_values)\n",
        "    len_system = len(system_values)\n",
        "    precision += (num_common_elems/len_system)\n",
        "    recall += (num_common_elems/len_gold)\n",
        "  precision = (1/n)*precision\n",
        "  recall = (1/n)*recall\n",
        "  F = 2 * ((precision*recall)/(precision+recall))\n",
        "  return precision, recall, F"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2eybIuitz3Co",
        "outputId": "345f01fc-07ef-45f1-9cf9-359a143e99c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "def b3_test():\n",
        "  gold={\"a1\":1, \"a2\": 2, \"a3\": 1, \"a4\":1, \"a5\": 3, \"a6\":3, \"a7\":2, \"a8\":2, \"a9\":1, \"a10\":1}\n",
        "  system={\"a1\":5, \"a2\": 6, \"a3\": 6, \"a4\":6, \"a5\": 7, \"a6\":7, \"a7\":5, \"a8\":5, \"a9\":5, \"a10\":8}\n",
        "\n",
        "  precision, recall, F=b3(gold, system)\n",
        "  print(\"P: %.3f, R: %.3f, F: %.3f\" % (precision, recall, F))\n",
        "\n",
        "  assert abs(precision-0.667) < 0.001\n",
        "  assert abs(recall-0.547) < 0.001\n",
        "  assert abs(F-0.601) < 0.001\n",
        "  \n",
        "  print (\"B3 sanity check passed\")\n",
        "b3_test()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "P: 0.667, R: 0.547, F: 0.601\n",
            "B3 sanity check passed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rNFaD5IO_P3F"
      },
      "source": [
        "### **Part 2. Neural coref**\n",
        "In part 2, the skeleton code for mention-ranking model is provided to you, you will not need to change any code until Part 2.1 begins. The following section provides the Mention class which is used to store relavant information about a mention and the BasicCorefModel. You will, at the very least, need to carefully read these two classes and understand the information stored in Mention and the structure of the model to complete this homework.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0dVP6JsQzghb",
        "colab": {}
      },
      "source": [
        "class Mention():\n",
        "\n",
        "  \"\"\"\n",
        "  An object to contain information about each mention\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, mention_id, docid, absolute_start_idx, absolute_end_idx, sentence_start_idx, sentence_end_idx, sentence, vocab):\n",
        "    self.docid=docid\n",
        "\n",
        "    # mention id (globally unique within one file, but not across different train and test files)\n",
        "    self.mention_id=mention_id\n",
        "    # the token index of the mention start position, measured from the beginning of the document\n",
        "    self.absolute_start_idx=absolute_start_idx\n",
        "    # the token index of the mention end position, measured from the beginning of the document\n",
        "    self.absolute_end_idx=absolute_end_idx\n",
        "    # the token index of the mention start position, measured from the beginning of the sentence\n",
        "    self.sentence_start_idx=sentence_start_idx\n",
        "    # the token index of the mention end position, measured from the beginning of the sentence\n",
        "    self.sentence_end_idx=sentence_end_idx\n",
        "    # a list of tokens for all the words in the mention's sentence\n",
        "    self.sentence=sentence\n",
        "    # a list of tokens ids for all the words in the mention's sentence\n",
        "    self.sentence_ids=[]\n",
        "    self.sentence_length=len(sentence)\n",
        "\n",
        "    for word in sentence:\n",
        "      word=word.lower()\n",
        "      self.sentence_ids.append(vocab[word] if word in vocab else vocab[\"[UNK]\"])\n",
        "   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "AQ3B8CU4AGvc",
        "colab": {}
      },
      "source": [
        "def convert_data_to_training_instances(all_sents, all_ents, vocab):\n",
        "  X=[]\n",
        "  Y=[]\n",
        "  M=[]\n",
        "\n",
        "  global_id=0\n",
        "  truth={}\n",
        "\n",
        "  for doc_idx, doc_ent in enumerate(all_ents):\n",
        "\n",
        "    current_token_position=0\n",
        "\n",
        "    existing_mentions=[]\n",
        "\n",
        "    for sent_idx, mention_list in enumerate(doc_ent):\n",
        "      sent=all_sents[doc_idx][sent_idx]\n",
        "\n",
        "      for mention_idx, mention in enumerate(mention_list):\n",
        "\n",
        "        start_sent_idx, end_sent_idx, entity_id, identifier=mention\n",
        "\n",
        "        mention=Mention(global_id, identifier, current_token_position+start_sent_idx, current_token_position+end_sent_idx, start_sent_idx, end_sent_idx, sent, vocab)\n",
        "        M.append(mention)\n",
        "        truth[global_id]=entity_id\n",
        "\n",
        "        global_id+=1\n",
        "\n",
        "        x=[]\n",
        "        y=[]\n",
        "\n",
        "        for aidx, antecedent in enumerate(existing_mentions):\n",
        "          x.append(antecedent)\n",
        "          if truth[antecedent.mention_id] == truth[mention.mention_id]:\n",
        "            y.append(aidx)\n",
        "\n",
        "        X.append(x)\n",
        "        Y.append(torch.LongTensor(y).to(device))\n",
        "\n",
        "        existing_mentions.append(mention)\n",
        "\n",
        "      current_token_position+=len(sent)\n",
        "\n",
        "  return X, Y, M, truth"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PYmOCaewzj3e",
        "colab": {}
      },
      "source": [
        "class BasicCorefModel(nn.Module):\n",
        "\n",
        "\tdef __init__(self, vocab, embeddings):\n",
        "\t\tsuper(BasicCorefModel, self).__init__()\n",
        "\n",
        "\t\tself.vocab=vocab\n",
        "\n",
        "\t\tself.embeddings = nn.Embedding.from_pretrained(embeddings)\n",
        "\n",
        "\t\t_, embedding_size=embeddings.shape\n",
        "\n",
        "\t\tself.hidden_dim=50\n",
        "\n",
        "\t\tself.input_size=2 * embedding_size\n",
        "\t\t# W1 = R^(2*embedding_size (E) X 50)\n",
        "\t\tself.W1 = nn.Linear(self.input_size, self.hidden_dim)\n",
        "\t\tself.tanh=nn.Tanh()\n",
        "\t\t# W2 = R^(50 X 1)\n",
        "\t\tself.W2 = nn.Linear(self.hidden_dim, 1)\t\n",
        "\n",
        "\tdef scorer(self, batch_x, batch_m):\n",
        "\n",
        "\t\t\"\"\"\n",
        "\t\tInput: a batch containing:\n",
        "\t\t\t-- batch_m [list of Mention objects]: mention to resolve.  batch_m[i] contains a single Mention\n",
        "\t\t\t-- batch_x [list of [list of Mention objects]]: candidate antecedents. batch_x[i] contains a list of candidate antecedents for mention batch_m[i]\n",
        "\n",
        "\t\tEach input batch is batched to contain the same number of candidate antecedents\n",
        "\n",
        "\t\tOutput: numpy matrix [batch_size, number_of_antecedents + 1, 1] containing scores for all antecedents\n",
        "\t\t\t-- for j < number_of_antecedents, output[i,j] contains the score of batch_x[i][j] being the correct antecedent for batch_m[i] \n",
        "\t\t\t-- for j == number_of_antecedents, output[i,j] = 0 (the score for batch_m[i] being linked to no antecedent)\n",
        "\t\tAbove is looping through mentions (i) while also looping through the candidate antecedents\n",
        "\t\t\"\"\"\n",
        "\n",
        "\t\tthis_batch_size=len(batch_x) # number of batches of mentions\n",
        "\t\tnum_ants=len(batch_x[0]) # number of candidate antecedents\n",
        "\n",
        "\t\t# get representations for mentions\n",
        "\t\tlastWordID=[]\n",
        "\n",
        "\t\tfor idx, mention in enumerate(batch_m): # for each mention\n",
        "\t\t\tlastWordID.append(mention.sentence_ids[mention.sentence_end_idx])\n",
        "\t \t\t\n",
        "\n",
        "\t\t# [this_batch_size, 1, embedding_size]\n",
        "\t\tmention_LW_embeddings=self.embeddings(torch.LongTensor(lastWordID).to(device)).unsqueeze(1)\n",
        "\n",
        "\t\t# get representations for antecedents\n",
        "\t\tantLastWords=[]\n",
        "\t\tfor idx in range(len(batch_x)):\n",
        "\t\t\tantWords=[]\n",
        "\t\t\tfor ant_idx, ant in enumerate(batch_x[idx]):\n",
        "\t\t\t\tantWords.append(ant.sentence_ids[ant.sentence_end_idx])\n",
        "\n",
        "\t\t\tantLastWords.append(antWords)\n",
        "\n",
        "\t\t# [this_batch_size, num_ants, embedding_size]\n",
        "\t\tantecedent_LW_embeddings=self.embeddings(torch.LongTensor(antLastWords).to(device))\n",
        "\n",
        "\t\t# We want to generate a score for each antecedent for each mention. However,\n",
        "\t\t# mention_LW_embeddings is [this_batch_size, 1, embedding_size] while,\n",
        "\t\t# antecedent_LW_embeddings is [this_batch_size, num_ants, embedding_size].\n",
        "\t\t# So let's make a bunch of copies of mention_LW_embeddings (one for each of its candidate antecedents)\n",
        "\n",
        "\t\t# [this_batch_size, num_ants, embedding_size]\n",
        "\t\tmention_LW_embeddings_copies=mention_LW_embeddings.expand_as(antecedent_LW_embeddings)\n",
        "\n",
        "\t\t# Now that they're the same size, we can concatenate them together into one big matrix\n",
        "\n",
        "\t\t# [this_batch_size, num_ants, (embedding_size + embedding_size)]\n",
        "\t\tall_features=torch.cat([mention_LW_embeddings_copies, antecedent_LW_embeddings], 2)\n",
        "\t\t\n",
        "\t\t# [this_batch_size, num_ants, 1]\n",
        "\t\tpreds=self.W2(self.tanh(self.W1(all_features))).squeeze(-1)\n",
        "\n",
        "\t\t# Let's fix the score for starting a new entity to be 0; all of the other scores for candidate antecedents will end up \n",
        "\t\t# being relative to that.\n",
        "\n",
        "\t\t# [this_batch_size, 1]\n",
        "\t\tzeros=torch.FloatTensor(np.zeros((this_batch_size, 1))).to(device)\n",
        "\n",
        "\t\t# [this_batch_size, num_ants + 1, 1]\t\t\n",
        "\t\tpreds=torch.cat((preds, zeros), 1)\n",
        "\n",
        "\t\treturn preds"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-oPEwL-wQfyf",
        "colab": {}
      },
      "source": [
        "######### HELPER FUNCTION FOR TRAINING STARTS #########\n",
        "#########  DONT'T EDIT THIS SECTION OF CODE   #########\n",
        "def forward_predict(batch_x, batch_m, scoring_function):\n",
        "\n",
        "  this_batch_size=len(batch_x)\n",
        "  num_ants=len(batch_x[0])\n",
        "\n",
        "  # if this batch has no antecedents, then it must start a new entity\n",
        "  if num_ants == 0:\n",
        "    return torch.LongTensor([0]*this_batch_size)\n",
        "  \n",
        "  # get predictions\n",
        "  preds=scoring_function(batch_x, batch_m)\n",
        "\n",
        "  # \n",
        "  arg_sorts=torch.argsort(preds, descending=True, dim=1)\n",
        "  tops=arg_sorts[:,0]\n",
        "\n",
        "  return tops\n",
        "\n",
        "\n",
        "def forward_train(batch_x, batch_y, batch_m, scoring_function):\n",
        "\n",
        "  num_batch=len(batch_x)\n",
        "  num_ants=len(batch_x[0])\n",
        "\n",
        "  # if this batch has no candidate antecedents, then each mention must start a new entity so there is only only choice we could make (hence no loss)\n",
        "  if num_ants == 0:\n",
        "    return None\n",
        "\n",
        "  preds=scoring_function(batch_x, batch_m)\n",
        "  preds_sum=torch.logsumexp(preds, 1)\n",
        "\n",
        "  running_loss=None\n",
        "\n",
        "\n",
        "  for i in range(num_batch):\n",
        "\n",
        "    # optimize marginal log-likelihood of true antecedents\n",
        "    if batch_y[i].nelement() == 0:\n",
        "      golds_sum=0.\n",
        "    else:\n",
        "      golds=torch.index_select(preds[i], 0, batch_y[i])\n",
        "      golds_sum=torch.logsumexp(golds, 0)\n",
        "\n",
        "    diff=preds_sum[i]-golds_sum\n",
        "\n",
        "    running_loss = diff if running_loss is None else running_loss + diff\n",
        "\n",
        "  return running_loss\n",
        "\n",
        "def get_batches(X, Y, M, batchsize):\n",
        "  sizes={}\n",
        "  for i in range(len(M)):\n",
        "    size=len(X[i])\n",
        "    if size not in sizes:\n",
        "      sizes[size]=[]\n",
        "    sizes[size].append((X[i], Y[i], M[i]))\n",
        "\n",
        "  batches=[]\n",
        "\n",
        "  for size in sizes:\n",
        "    i=0\n",
        "    while (i < len(sizes[size])):\n",
        "\n",
        "      data=sizes[size][i:i+batchsize]\n",
        "      batch_x=[]\n",
        "      batch_y=[]\n",
        "      batch_m=[]\n",
        "      for x, y, m in data:\n",
        "        batch_x.append(x)\n",
        "        batch_y.append(y)\n",
        "        batch_m.append(m)\n",
        "\n",
        "      batches.append((batch_x, batch_y, batch_m))\n",
        "      i+=batchsize\n",
        "\n",
        "  return batches\n",
        "\n",
        "\n",
        "def train(X, Y, M, train_gold, test_X, test_Y, test_M, test_gold, model):\n",
        "\n",
        "  batches=get_batches(X, Y, M, 32)\n",
        "  test_batches=get_batches(test_X, test_Y, test_M, 32)\n",
        "  optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "  for epoch in range(10):\n",
        "\n",
        "    model.train()\n",
        "    # train\n",
        "    bigloss=0.\n",
        "    for batch_x, batch_y, batch_m in batches:\n",
        "      model.zero_grad()\n",
        "      loss=forward_train(batch_x, batch_y, batch_m, model.scorer)\n",
        "      if loss is not None:\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        bigloss+=loss\n",
        "\n",
        "    # evaluate\n",
        "    model.eval()\n",
        "\n",
        "    gold={}\n",
        "    predicted={}\n",
        "\n",
        "    eid=0\n",
        "    tot=0\n",
        "\n",
        "    for batch_x, batch_y, batch_m in test_batches:\n",
        "      predictions=forward_predict(batch_x, batch_m, model.scorer)\n",
        "\n",
        "      for idx, mention in enumerate(batch_m):\n",
        "\n",
        "        gold[mention.docid, mention.absolute_start_idx, mention.absolute_end_idx]=test_gold[mention.mention_id]\n",
        "        prediction=predictions[idx]\n",
        "        tot+=1\n",
        "      \n",
        "        # prediction is to start a new entity\n",
        "        if prediction >= len(batch_x[idx]):\n",
        "          predicted[mention.docid, mention.absolute_start_idx, mention.absolute_end_idx]=eid\n",
        "          eid+=1\n",
        "\n",
        "        # prediction is to link to a previous mention\n",
        "        else:\n",
        "\n",
        "          best_antecedent=batch_x[idx][prediction]\n",
        "          predicted_entity_id=predicted[best_antecedent.docid, best_antecedent.absolute_start_idx, best_antecedent.absolute_end_idx]\n",
        "          predicted[mention.docid, mention.absolute_start_idx, mention.absolute_end_idx]=predicted_entity_id\n",
        "\n",
        "    P, R, F=b3(gold, predicted)\n",
        "    print(\"loss: %.3f, B3 F: %.3f, unique entities: %s, num mentions: %s\" % (bigloss, F, eid, tot))\n",
        "\n",
        "def set_seed(seed):\n",
        "  \"\"\"\n",
        "  Sets random seeds and sets model in deterministic\n",
        "  training mode. Ensures reproducible results\n",
        "  \"\"\"\n",
        "  torch.manual_seed(seed)\n",
        "  torch.backends.cudnn.deterministic = True\n",
        "  torch.backends.cudnn.benchmark = False\n",
        "  np.random.seed(seed)\n",
        "######### HELPER FUNCTION FOR TRAINING ENDS #########\n",
        "#########  DONT'T EDIT THIS SECTION OF CODE   #########"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "b7_H0_p-bHhp"
      },
      "source": [
        "Now, everything is set up to run the BasicCorefModel. Let's run the cell below to train the model and look at the result of the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lnvgFWdPblQ_",
        "outputId": "2f9a522a-2ea7-4fa8-8ff3-4d9178ddfd75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "X, Y, M, train_truth=convert_data_to_training_instances(all_sents, all_ents, vocab)\n",
        "dev_X, dev_Y, dev_M, dev_truth=convert_data_to_training_instances(dev_all_sents, dev_all_ents, vocab)\n",
        "set_seed(159)\n",
        "model=BasicCorefModel(vocab, embeddings)\n",
        "model=model.to(device)\n",
        "print (\"Training BasicCorefModel\")\n",
        "train(X, Y, M, train_truth, dev_X, dev_Y, dev_M, dev_truth, model)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training BasicCorefModel\n",
            "loss: 41274.820, B3 F: 0.764, unique entities: 29578, num mentions: 29597\n",
            "loss: 33196.121, B3 F: 0.764, unique entities: 29569, num mentions: 29597\n",
            "loss: 29578.078, B3 F: 0.765, unique entities: 29323, num mentions: 29597\n",
            "loss: 27773.998, B3 F: 0.771, unique entities: 28797, num mentions: 29597\n",
            "loss: 26788.646, B3 F: 0.779, unique entities: 27948, num mentions: 29597\n",
            "loss: 26151.426, B3 F: 0.782, unique entities: 27427, num mentions: 29597\n",
            "loss: 25682.389, B3 F: 0.783, unique entities: 27372, num mentions: 29597\n",
            "loss: 25319.139, B3 F: 0.786, unique entities: 26932, num mentions: 29597\n",
            "loss: 25024.688, B3 F: 0.789, unique entities: 26854, num mentions: 29597\n",
            "loss: 24776.924, B3 F: 0.793, unique entities: 26450, num mentions: 29597\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hi-A_Ho9P3bl"
      },
      "source": [
        "### **Part 2.1 Incorporate distance**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "718TVDuESx4G"
      },
      "source": [
        "In this part, you should incorporate the word distance information to BasicCorefModel described in the HW. The below code structure provided to you is exactly the same as BasicCorefModel, your job is to add code into both __init__() and scorer() functions as you see fit.\n",
        "\n",
        "Hint: You might consider initialize distance embedding in __init__() function, then concatenate the original embedding and the corresponding distance embedding in scorer(). \n",
        "\n",
        "After implementing this, run the sanity check, test_distance(), provided to you."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "04w8HtOHzm25",
        "colab": {}
      },
      "source": [
        "class DistanceCorefModel(nn.Module):\n",
        "\n",
        "\t\"\"\" The code provided here starts out as just a copy of BasicCorefModel \"\"\"\n",
        "\n",
        "\t'''\n",
        "\tclass Mention():\n",
        "\t  # mention id (globally unique within one file, but not across different train and test files)\n",
        "    self.mention_id=mention_id\n",
        "\n",
        "    # the token index of the mention START position, measured from the beginning of the document\n",
        "    self.absolute_start_idx=absolute_start_idx\n",
        "\n",
        "    # the token index of the mention END position, measured from the beginning of the document\n",
        "    self.absolute_end_idx=absolute_end_idx\n",
        "\n",
        "    # the token index of the mention START position, measured from the beginning of the sentence\n",
        "    self.sentence_start_idx=sentence_start_idx\n",
        "\n",
        "    # the token index of the mention END position, measured from the beginning of the sentence\n",
        "    self.sentence_end_idx=sentence_end_idx\n",
        "\n",
        "    # a list of tokens for ALL the words in the mention's sentence\n",
        "    self.sentence=sentence\n",
        "\n",
        "    # a list of tokens ids for ALL the words in the mention's sentence\n",
        "    self.sentence_ids=[]\n",
        "    self.sentence_length=len(sentence)\n",
        "\n",
        "    for word in sentence:\n",
        "      word=word.lower()\n",
        "      self.sentence_ids.append(vocab[word] if word in vocab else vocab[\"[UNK]\"])\n",
        "\t'''\n",
        "\n",
        "\n",
        "\tdef __init__(self, vocab, embeddings):\n",
        "\t\tsuper(DistanceCorefModel, self).__init__()\n",
        "\n",
        "\t\tself.vocab=vocab\n",
        "\n",
        "\t\tself.embeddings = nn.Embedding.from_pretrained(embeddings)\n",
        "\t\n",
        "\t\t#initialize distance embeddings from something\n",
        "\t\t#self.distance_embeddings = nn.Embedding.from_pretrained(embeddings)\n",
        "\t\t\n",
        "\t\t#self.distance_embeddings = nn.Embedding.from_pretrained(torch.eye(10))\n",
        "\t\t#_, distance_embedding_size = self.distance_embeddings.shape\n",
        "\n",
        "\t\t_, embedding_size = embeddings.shape\n",
        "\n",
        "\t\tself.hidden_dim = 50\n",
        "\t\tself.input_size = (2 * embedding_size) + 10 # (2E+D) X 50\n",
        "\t\tself.W1 = nn.Linear(self.input_size, self.hidden_dim)\n",
        "\t\tself.tanh=nn.Tanh()\n",
        "\t\tself.W2 = nn.Linear(self.hidden_dim, 1)\t\n",
        "\t\tself.distance_embeddings = nn.Embedding(10,10)\n",
        "\n",
        "\tdef scorer(self, batch_x, batch_m):\n",
        "\n",
        "\t\t\"\"\"\n",
        "\t\tInput: a batch containing:\n",
        "\t\t\t-- batch_m [list of Mention objects]: mention to resolve.  batch_m[i] contains a single Mention\n",
        "\t\t\t-- batch_x [list of [list of Mention objects]]: candidate antecedents. batch_x[i] contains a list of candidate antecedents for mention batch_m[i]\n",
        "\n",
        "\t\tEach input batch is batched to contain the same number of candidate antecedents\n",
        "\n",
        "\t\tOutput: numpy matrix [batch_size, number_of_antecedents + 1, 1] containing scores for all antecedents\n",
        "\t\t\t-- for j < number_of_antecedents, output[i,j] contains the score of batch_x[i][j] being the correct antecedent for batch_m[i] \n",
        "\t\t\t-- for j == number_of_antecedents, output[i,j] = 0 (the score for batch_m[i] being linked to no antecedent)\n",
        "\n",
        "\t\t\"\"\"\n",
        "\t\tdevice = torch.device(\"cpu\")\n",
        "\n",
        "\t\tthis_batch_size=len(batch_x) # number of mentions\n",
        "\t\tnum_ants=len(batch_x[0])\n",
        "\t\t#print('this btch size',this_batch_size)\n",
        "\t\t#print('num ants',num_ants)\n",
        "\n",
        "\t\t# get representations for mentions\n",
        "\t\tlastWordID=[]\n",
        "\n",
        "\t\tfor idx, mention in enumerate(batch_m): # for each mention\n",
        "\t\t\tlastWordID.append(mention.sentence_ids[mention.sentence_end_idx])\n",
        "\t\t\t# get the index of word at the token index of the mention end position (sentence)\n",
        "\n",
        "\t\t# [this_batch_size, 1, embedding_size] --> representation for mentions (embeddings)\n",
        "\t\tmention_LW_embeddings=self.embeddings(torch.LongTensor(lastWordID).to(device)).unsqueeze(1)\n",
        "\t\t#print('mention embeddings',mention_LW_embeddings.shape)\n",
        "\t\t# get representations for antecedents\n",
        "\t\tantLastWords=[]\n",
        "\t\tfor idx in range(len(batch_x)):\n",
        "\t\t\tantWords=[]\n",
        "\t\t\tfor ant_idx, ant in enumerate(batch_x[idx]):\n",
        "\t\t\t\tantWords.append(ant.sentence_ids[ant.sentence_end_idx])\n",
        "\t\t\t#print('antwords this batch',len(antWords))\n",
        "\t \t\t#print('num ants',len(antWords))\n",
        "\t\t\tantLastWords.append(antWords)\n",
        "\t \t\n",
        "\t\t# [this_batch_size, num_ants, embedding_size] --> representation for antecedents (embeddings) for all mentions\n",
        "\t\tantecedent_LW_embeddings=self.embeddings(torch.LongTensor(antLastWords).to(device))\n",
        "\t\t#print('ant embeddings',antecedent_LW_embeddings.shape)\n",
        "\t\t# We want to generate a score for each antecedent for each mention. However,\n",
        "\t\t# mention_LW_embeddings is [this_batch_size, 1, embedding_size] while,\n",
        "\t\t# antecedent_LW_embeddings is [this_batch_size, num_ants, embedding_size]. \n",
        "\t\t# LOTS more antecedents than mentions cuz repeats?\n",
        "\t\t# So let's make a bunch of copies of mention_LW_embeddings (one for each of its candidate antecedents)\n",
        "\n",
        "\t\t# [this_batch_size, num_ants, embedding_size]\n",
        "\t\tmention_LW_embeddings_copies=mention_LW_embeddings.expand_as(antecedent_LW_embeddings)\n",
        "\t\t# Now that they're the same size, we can concatenate them together into one big matrix\n",
        "\t\t\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\t\t# mention_abs_end_embeddings=self.embeddings(torch.LongTensor(doc_lastwordID).to(device)).unsqueeze(1)\n",
        "\t\t#print('list of mentions',doc_mention_lastwordID)\n",
        "\t\t#print(len(doc_mention_lastwordID)) # 32\n",
        "\t\t# compile all the absolute end indices for each antecedent\n",
        "\t\t\n",
        "\t\t# DISTANCE EMBEDDING CREATION\n",
        "\t\t# lastWordID.append(mention.sentence_ids[mention.sentence_end_idx])\n",
        "\t\t\n",
        "\t\t# compile all the absolute end indices for each mention\n",
        "\t\tdoc_mention_lastwordID = []\n",
        "\t\tfor idx,mention in enumerate(batch_m):\n",
        "\t\t\t#doc_mention_lastwordID.append(mention.sentence_ids[mention.absolute_end_idx])\n",
        "\t\t\tdoc_mention_lastwordID.append(mention.absolute_end_idx)\n",
        "\t \n",
        "\t\tdoc_ant_lastwordID = []\n",
        "\t\tfor idx in range(len(batch_x)):\n",
        "\t\t\tantWords=[]\n",
        "\t\t\t#for ant_idx, ant in enumerate(batch_x[idx]):\n",
        "\t\t\t\t#antWords.append(ant.sentence_ids[ant.absolute_end_idx])\n",
        "\t\t\t\t#antWords.append(ant.absolute_end_idx)\n",
        "\t\t\tfor antecedent in batch_x[idx]:\n",
        "\t\t\t\t#print('antecendent',antecedent)\n",
        "\t\t\t\tantWords.append(antecedent.absolute_end_idx) # adding to list of antecedents\n",
        "\t\t\tdoc_ant_lastwordID.append(antWords)\n",
        "\t  #print('list of antecedents based on mention index',doc_ant_lastwordID)\n",
        "\t\tabs_diff = 0\n",
        "\t\tabs_total = []\n",
        "\t\t#for idx,mention in enumerate(batch_m):\n",
        "\t\tfor word_mention_idx in range(len(doc_mention_lastwordID)): #indices, 32\n",
        "\t\t\tabs_diff_list = []\n",
        "\t\t\tfor word_ant_idx in range(len(doc_ant_lastwordID[word_mention_idx])): # 1 X 10\n",
        "\t\t\t\tdiff = doc_mention_lastwordID[word_mention_idx] - doc_ant_lastwordID[word_mention_idx][word_ant_idx]\n",
        "\t\t\t\t#diff = doc_mention_lastwordID[word_mention_idx]\n",
        "\t\t\t\tabs_diff = abs(diff)\n",
        "\t\t\t\tif abs_diff == 0:\n",
        "\t\t\t\t\t\tabs_diff_list.append(0)\n",
        "\t\t\t\telif abs_diff == 1:\n",
        "\t\t\t\t\t\tabs_diff_list.append(1)\n",
        "\t\t\t\telif abs_diff == 2:\n",
        "\t\t\t\t\t\tabs_diff_list.append(2)\n",
        "\t\t\t\telif abs_diff == 3:\n",
        "\t\t\t\t\t\tabs_diff_list.append(3)\n",
        "\t\t\t\telif abs_diff == 4:\n",
        "\t\t\t\t\t\tabs_diff_list.append(4)\n",
        "\t\t\t\telif abs_diff <= 7 and abs_diff >= 5:\n",
        "\t\t\t\t\t\tabs_diff_list.append(5)\n",
        "\t\t\t\telif abs_diff <= 15 and abs_diff >= 8:\n",
        "\t\t\t\t\t\tabs_diff_list.append(6)\n",
        "\t\t\t\telif abs_diff <= 31 and abs_diff >= 16:\n",
        "\t\t\t\t\t\tabs_diff_list.append(7)\n",
        "\t\t\t\telif abs_diff <= 63 and abs_diff >= 32:\n",
        "\t\t\t\t\t\tabs_diff_list.append(8)\n",
        "\t\t\t\telse:\n",
        "\t\t\t\t\t\tabs_diff_list.append(9)\n",
        "\t\t\tabs_total.append(abs_diff_list) # 32, 1\n",
        "\t\tabs_distance_embeddings = self.distance_embeddings(torch.LongTensor(abs_total).to(device))\n",
        "\t\tall_features=torch.cat([mention_LW_embeddings_copies, antecedent_LW_embeddings,abs_distance_embeddings], 2)\n",
        "\t\t#print('distance embedding',abs_distance_embeddings.shape) # should be [32,1,10]\n",
        "\t\t# [32, 1, 110]\n",
        "\t\t# [this_batch_size, num_ants, (embedding_size + embedding_size + distance_embedding_size)]\n",
        "\t\t# concatenate these newly adjusted embeddings for a 2-dimensional space\n",
        "\t\t#print('mention',mention_LW_embeddings_copies.shape)\n",
        "\t\t#print('ant',antecedent_LW_embeddings.shape)\n",
        "\t\t#print('abs dist',abs_distance_embeddings.shape)\n",
        "\t\t\n",
        "\t\t#print('all features',all_features.shape)\n",
        "\t\n",
        "\t\t# [this_batch_size, num_ants, 1]\n",
        "\t\tpreds=self.W2(self.tanh(self.W1(all_features))).squeeze(-1)\n",
        "\n",
        "\t\t# Let's fix the score for starting a new entity to be 0; all of the other scores for candidate antecedents will end up \n",
        "\t\t# being relative to that.\n",
        "\n",
        "\t\t# [this_batch_size, 1]\n",
        "\t\tzeros=torch.FloatTensor(np.zeros((this_batch_size, 1))).to(device)\n",
        "\n",
        "\t\t# [this_batch_size, num_ants + 1, 1]\t\t\n",
        "\t\tpreds=torch.cat((preds, zeros), 1)\n",
        "\t\treturn preds"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iym9YsLOROHV",
        "colab": {}
      },
      "source": [
        "def test_distance(model):\n",
        "  batch_x=[]\n",
        "  maxLen=100\n",
        "  for i in range(maxLen):\n",
        "    mention=Mention(i, \"testdoc\", i, i+1, 0, 1, [\"John\", \"Smith\", \"is\", \"a\", \"person\"], model.vocab)\n",
        "    batch_x.append(mention)\n",
        "\n",
        "  mention=Mention(maxLen, \"testdoc\", maxLen, maxLen, 0, 0, [\"He\", \"is\", \"a\", \"person\"], model.vocab)\n",
        "\n",
        "  preds=model.scorer([batch_x], [mention])\n",
        "  preds=preds.detach().cpu().numpy()[0]\n",
        "  spearman, _=spearmanr(preds, np.arange(len(preds)))\n",
        "  print(\"Distance check: %.3f\" % spearman)\n",
        "  with open(\"distance_predictions.txt\", \"w\", encoding=\"utf-8\") as out:\n",
        "    out.write(' '.join([\"%.5f\" % x for x in preds]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iwVahwYxRVo-",
        "outputId": "eb26803e-25c9-4cb3-900c-9ea8c0e8f8dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "set_seed(159)\n",
        "model=DistanceCorefModel(vocab, embeddings)\n",
        "model=model.to(device)\n",
        "print (\"Training DistanceCorefModel\")\n",
        "train(X, Y, M, train_truth, dev_X, dev_Y, dev_M, dev_truth, model)\n",
        "test_distance(model)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training DistanceCorefModel\n",
            "loss: 38109.875, B3 F: 0.769, unique entities: 27403, num mentions: 29597\n",
            "loss: 31399.088, B3 F: 0.792, unique entities: 25583, num mentions: 29597\n",
            "loss: 27612.166, B3 F: 0.806, unique entities: 24815, num mentions: 29597\n",
            "loss: 25193.537, B3 F: 0.810, unique entities: 24451, num mentions: 29597\n",
            "loss: 23620.645, B3 F: 0.812, unique entities: 24191, num mentions: 29597\n",
            "loss: 22586.162, B3 F: 0.815, unique entities: 23948, num mentions: 29597\n",
            "loss: 21875.182, B3 F: 0.816, unique entities: 23776, num mentions: 29597\n",
            "loss: 21347.727, B3 F: 0.817, unique entities: 23646, num mentions: 29597\n",
            "loss: 20928.213, B3 F: 0.817, unique entities: 23497, num mentions: 29597\n",
            "loss: 20579.402, B3 F: 0.819, unique entities: 23437, num mentions: 29597\n",
            "Distance check: 0.943\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "OPy6ps0sSED9"
      },
      "source": [
        "### **Part 2.2 Design a fancier model**\n",
        "Here comes the fun part! After completing DistanceCorefModel, you have certain degree of familiarity with the model architecture. In the section, you will be implementing a fancier model using any features you'd like. Feel free to make changes to the architecture you see fit.\n",
        "\n",
        "Submit this notebook to gradescope and a writeup file \"fancymodel.txt\" describing your model and the features you use.\n",
        "**Your code must implement exactly what you describe in your writeup**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4Tbubxvkzqoo",
        "colab": {}
      },
      "source": [
        "class FancyCorefModel(nn.Module):\n",
        "\n",
        "\t\"\"\" The code provided here starts out as just a copy of BasicCorefModel \"\"\"\n",
        "\n",
        "\tdef __init__(self, vocab, embeddings):\n",
        "\t\tsuper(FancyCorefModel, self).__init__()\n",
        "\n",
        "\t\tself.vocab=vocab\n",
        "\n",
        "\t\tself.embeddings = nn.Embedding.from_pretrained(embeddings)\n",
        "\n",
        "\t\t_, embedding_size=embeddings.shape\n",
        "\t\tself.hidden_dim = 50\n",
        "\t\tself.input_size = (2 * embedding_size) + 10 + 10 + 4 + 3# (2E+D) X 50\n",
        "\t\tself.W1 = nn.Linear(self.input_size, self.hidden_dim)\n",
        "\t\tself.tanh=nn.Tanh()\n",
        "\t\tself.W2 = nn.Linear(self.hidden_dim, 1)\t\n",
        "\t\tself.mention_width_embeddings = nn.Embedding(10,10)\n",
        "\t\tself.distance_embeddings = nn.Embedding(10,10)\n",
        "\t\tself.gender_embeddings = nn.Embedding(4,4) #she,he,they\n",
        "\t\tself.number_embeddings = nn.Embedding(3,3) #she/he versus they\n",
        "\tdef scorer(self, batch_x, batch_m):\n",
        "\n",
        "\t\t\"\"\"\n",
        "\t\tInput: a batch containing:\n",
        "\t\t\t-- batch_m [list of Mention objects]: mention to resolve.  batch_m[i] contains a single Mention\n",
        "\t\t\t-- batch_x [list of [list of Mention objects]]: candidate antecedents. batch_x[i] contains a list of candidate antecedents for mention batch_m[i]\n",
        "\n",
        "\t\tEach input batch is batched to contain the same number of candidate antecedents\n",
        "\n",
        "\t\tOutput: numpy matrix [batch_size, number_of_antecedents + 1, 1] containing scores for all antecedents\n",
        "\t\t\t-- for j < number_of_antecedents, output[i,j] contains the score of batch_x[i][j] being the correct antecedent for batch_m[i] \n",
        "\t\t\t-- for j == number_of_antecedents, output[i,j] = 0 (the score for batch_m[i] being linked to no antecedent)\n",
        "\n",
        "\t\t\"\"\"\n",
        "\t\t\n",
        "\t\tthis_batch_size=len(batch_x)\n",
        "\t\tnum_ants=len(batch_x[0])\n",
        "\n",
        "\t\t# get representations for mentions \n",
        "\t\tlastWordID=[]\n",
        "\n",
        "\t\tfor idx, mention in enumerate(batch_m):\n",
        "\t\t\tlastWordID.append(mention.sentence_ids[mention.sentence_end_idx])\n",
        "\n",
        "\t\t# [this_batch_size, 1, embedding_size]\n",
        "\t\tmention_LW_embeddings=self.embeddings(torch.LongTensor(lastWordID).to(device)).unsqueeze(1)\n",
        "\n",
        "\t\t# get representations for antecedents\n",
        "\t\tantLastWords=[]\n",
        "\t\tfor idx in range(len(batch_x)):\n",
        "\t\t\tantWords=[]\n",
        "\t\t\tfor ant_idx, ant in enumerate(batch_x[idx]):\n",
        "\t\t\t\tantWords.append(ant.sentence_ids[ant.sentence_end_idx])\n",
        "\n",
        "\t\t\tantLastWords.append(antWords)\n",
        "\n",
        "\t\t# [this_batch_size, num_ants, embedding_size]\n",
        "\t\tantecedent_LW_embeddings=self.embeddings(torch.LongTensor(antLastWords).to(device))\n",
        "\n",
        "\t\t# We want to generate a score for each antecedent for each mention. However,\n",
        "\t\t# mention_LW_embeddings is [this_batch_size, 1, embedding_size] while,\n",
        "\t\t# antecedent_LW_embeddings is [this_batch_size, num_ants, embedding_size].\n",
        "\t\t# So let's make a bunch of copies of mention_LW_embeddings (one for each of its candidate antecedents)\n",
        "\n",
        "\t\t# [this_batch_size, num_ants, embedding_size]\n",
        "\t\tmention_LW_embeddings_copies=mention_LW_embeddings.expand_as(antecedent_LW_embeddings)\n",
        "\n",
        "\t\t# Now that they're the same size, we can concatenate them together into one big matrix\n",
        "\n",
        "\t\t# IMPLEMENT FANCY COREFERENCE MODEL HERE\n",
        "\t\t# Grab each span i and assign each an antecedent, where each possible antecedent goes from start-i\n",
        "\t\t# Maybe use a BiLSTM? \n",
        "\t\t# Maybe incorporate attention into the model\n",
        "\t\t# Impt features: context of spans and the internal info of a span\n",
        "\t\t# We also include an attention mechanism over words in each span to model head words\n",
        "\n",
        "\t\t# IMPLEMENT DISTANCE COREF FEATURES\n",
        "\t\tdoc_mention_lastwordID = []\n",
        "\t\tfor idx,mention in enumerate(batch_m):\n",
        "\t\t\tdoc_mention_lastwordID.append(mention.absolute_end_idx)\n",
        "\t \n",
        "\t\tdoc_ant_lastwordID = []\n",
        "\t\tfor idx in range(len(batch_x)):\n",
        "\t\t\tantWords=[]\n",
        "\t\t\tfor antecedent in batch_x[idx]:\n",
        "\t\t\t\tantWords.append(antecedent.absolute_end_idx) # adding to list of antecedents\n",
        "\t\t\tdoc_ant_lastwordID.append(antWords)\n",
        "\t\tabs_diff = 0\n",
        "\t\tabs_total = []\n",
        "\t\tfor word_mention_idx in range(len(doc_mention_lastwordID)): #indices, 32\n",
        "\t\t\tabs_diff_list = []\n",
        "\t\t\tfor word_ant_idx in range(len(doc_ant_lastwordID[word_mention_idx])): # 1 X 10\n",
        "\t\t\t\tdiff = doc_mention_lastwordID[word_mention_idx] - doc_ant_lastwordID[word_mention_idx][word_ant_idx]\n",
        "\t\t\t\tabs_diff = abs(diff)\n",
        "\t\t\t\tif abs_diff == 0:\n",
        "\t\t\t\t\t\tabs_diff_list.append(0)\n",
        "\t\t\t\telif abs_diff == 1:\n",
        "\t\t\t\t\t\tabs_diff_list.append(1)\n",
        "\t\t\t\telif abs_diff == 2:\n",
        "\t\t\t\t\t\tabs_diff_list.append(2)\n",
        "\t\t\t\telif abs_diff == 3:\n",
        "\t\t\t\t\t\tabs_diff_list.append(3)\n",
        "\t\t\t\telif abs_diff == 4:\n",
        "\t\t\t\t\t\tabs_diff_list.append(4)\n",
        "\t\t\t\telif abs_diff <= 7 and abs_diff >= 5:\n",
        "\t\t\t\t\t\tabs_diff_list.append(5)\n",
        "\t\t\t\telif abs_diff <= 15 and abs_diff >= 8:\n",
        "\t\t\t\t\t\tabs_diff_list.append(6)\n",
        "\t\t\t\telif abs_diff <= 31 and abs_diff >= 16:\n",
        "\t\t\t\t\t\tabs_diff_list.append(7)\n",
        "\t\t\t\telif abs_diff <= 63 and abs_diff >= 32:\n",
        "\t\t\t\t\t\tabs_diff_list.append(8)\n",
        "\t\t\t\telse:\n",
        "\t\t\t\t\t\tabs_diff_list.append(9)\n",
        "\t\t\tabs_total.append(abs_diff_list) # 32, 1\n",
        "\t\tabs_distance_embeddings = self.distance_embeddings(torch.LongTensor(abs_total).to(device))\n",
        "\t\t#print('dist',abs_distance_embeddings)\n",
        "\n",
        "\t\t# SPAN WIDTH + DISTANCE BTWN SPANS\n",
        "\t\ttotal_span_widths = []\n",
        "\t\tfor index in range(len(batch_x)):\n",
        "\t\t\tspan_widths = []\n",
        "\t\t\tfor ant in range(len(batch_x[index])):\n",
        "\t\t\t\twidth_mention = abs(batch_m[index].sentence_start_idx - batch_m[index].sentence_end_idx)\n",
        "\t\t\t\twidth_ant = abs(batch_x[index][ant].sentence_start_idx - batch_x[index][ant].sentence_end_idx)\n",
        "\t\t\t\twidth = abs(width_mention-width_ant)\n",
        "\t\t\t\tif width == 0:\n",
        "\t\t\t\t\tspan_widths.append(0)\n",
        "\t\t\t\telif width == 1:\n",
        "\t\t\t\t\tspan_widths.append(1)\n",
        "\t\t\t\telif width == 2:\n",
        "\t\t\t\t\tspan_widths.append(2)\n",
        "\t\t\t\telif width == 3:\n",
        "\t\t\t\t\tspan_widths.append(3)\n",
        "\t\t\t\telif width == 4:\n",
        "\t\t\t\t\tspan_widths.append(4)\n",
        "\t\t\t\telif width >= 5 and width <= 7:\n",
        "\t\t\t\t\tspan_widths.append(5)\n",
        "\t\t\t\telif width >= 8 and width <= 15:\n",
        "\t\t\t\t\tspan_widths.append(6)\n",
        "\t\t\t\telif width >= 16 and width <= 31:\n",
        "\t\t\t\t\tspan_widths.append(7)\n",
        "\t\t\t\telif width >= 32 and width <= 63:\n",
        "\t\t\t\t\tspan_widths.append(8)\n",
        "\t\t\t\telse:\n",
        "\t\t\t\t\tspan_widths.append(9)\n",
        "\t\t\ttotal_span_widths.append(span_widths)\n",
        "\t\tmention_width_embeddings = self.mention_width_embeddings(torch.LongTensor(total_span_widths).to(device))\n",
        "\t\t#print('width',mention_width_embeddings)\n",
        "\t\t\n",
        "\t\t# GENDER AGREEMENT\n",
        "\t\ttotal_genders = []\n",
        "\t\tfor index in range(len(batch_x)):\n",
        "\t\t\tgenders = []\n",
        "\t\t\tfor ant in range(len(batch_x[index])):\n",
        "\t\t\t\tif (\"she\" or \"her\") in batch_x[index][ant].sentence:\n",
        "\t\t\t\t\t#print(batch_x[index][ant].sentence)\n",
        "\t\t\t\t\tgenders.append(0)\n",
        "\t\t\t\telif (\"he\" or \"him\") in batch_x[index][ant].sentence:\n",
        "\t\t\t\t\tgenders.append(1)\n",
        "\t\t\t\telif (\"they\") in batch_x[index][ant].sentence:\n",
        "\t\t\t\t\tgenders.append(2)\n",
        "\t\t\t\telse:\n",
        "\t\t\t\t\tgenders.append(3)\n",
        "\t\t\ttotal_genders.append(genders)\n",
        "\t\tgender_embeddings = self.gender_embeddings(torch.LongTensor(total_genders).to(device))\n",
        "\t\t\n",
        "\t\t# NUMBER AGREEMENT\n",
        "\t\t\n",
        "\t\ttotal_numbers = []\n",
        "\t\tfor index in range(len(batch_x)):\n",
        "\t\t\tnumbers = []\n",
        "\t\t\tfor ant in range(len(batch_x[index])):\n",
        "\t\t\t\tif (\"she\" or \"her\" or \"he\" or \"him\") in batch_x[index][ant].sentence:\n",
        "\t\t\t\t\tnumbers.append(0)\n",
        "\t\t\t\telif (\"they\") in batch_x[index][ant].sentence:\n",
        "\t\t\t\t\tnumbers.append(1)\n",
        "\t\t\t\telse:\n",
        "\t\t\t\t\tnumbers.append(2)\n",
        "\t\t\ttotal_numbers.append(numbers)\n",
        "\t\tnumber_embeddings = self.number_embeddings(torch.LongTensor(total_numbers).to(device))\n",
        "\t\t\n",
        "\t\t# ALL FEATURES\n",
        "\t\tall_features=torch.cat([mention_LW_embeddings_copies, antecedent_LW_embeddings,abs_distance_embeddings,mention_width_embeddings,gender_embeddings,number_embeddings], 2)\n",
        "\t\n",
        "\t\t# [this_batch_size, num_ants, 1]\n",
        "\t\tpreds=self.W2(self.tanh(self.W1(all_features))).squeeze(-1)\n",
        "\t\tzeros=torch.FloatTensor(np.zeros((this_batch_size, 1))).to(device)\n",
        "\n",
        "\t\t# [this_batch_size, num_ants + 1, 1]\t\t\n",
        "\t\tpreds=torch.cat((preds, zeros), 1)\n",
        "\n",
        "\t\treturn preds"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3uqdJ0085XoO",
        "outputId": "170482df-589c-4aab-fe90-de656bd6b5c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "model=FancyCorefModel(vocab, embeddings)\n",
        "model=model.to(device)\n",
        "\n",
        "print (\"Training FancyCorefModel\")\n",
        "train(X, Y, M, train_truth, dev_X, dev_Y, dev_M, dev_truth, model)\n",
        "test_distance(model)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training FancyCorefModel\n",
            "loss: 35070.379, B3 F: 0.793, unique entities: 25592, num mentions: 29597\n",
            "loss: 28207.088, B3 F: 0.812, unique entities: 24530, num mentions: 29597\n",
            "loss: 24093.018, B3 F: 0.821, unique entities: 23934, num mentions: 29597\n",
            "loss: 21733.496, B3 F: 0.827, unique entities: 23453, num mentions: 29597\n",
            "loss: 20391.447, B3 F: 0.831, unique entities: 23107, num mentions: 29597\n",
            "loss: 19530.891, B3 F: 0.835, unique entities: 22924, num mentions: 29597\n",
            "loss: 18914.557, B3 F: 0.836, unique entities: 22795, num mentions: 29597\n",
            "loss: 18440.221, B3 F: 0.837, unique entities: 22648, num mentions: 29597\n",
            "loss: 18057.422, B3 F: 0.838, unique entities: 22623, num mentions: 29597\n",
            "loss: 17737.248, B3 F: 0.838, unique entities: 22596, num mentions: 29597\n",
            "Distance check: 0.932\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Wu73DIyWAEM_",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}